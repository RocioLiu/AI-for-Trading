{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPr61+1zREb13YQJ5eQMSDo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RocioLiu/AI-for-Trading/blob/main/Simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydKfuCFn_APG"
      },
      "source": [
        "# **Simple RNN**\n",
        "In this notebook, we're going to train a simple RNN to do **time-series prediction**. Given some set of input data, it should be able to generate a prediction for the next time step!\n",
        "![](https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/231590b713d54096cbd4cdf8944750517faa13d2/recurrent-neural-networks/time-series/assets/time_prediction.png)\n",
        "\n",
        "* First, we'll create our data\n",
        "* Then, define an RNN in PyTorch\n",
        "* Finally, we'll train our network and see how it performs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9utQM8dH_oIL"
      },
      "source": [
        "### **Import resources and create data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXW_et-b-znV"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XKKT41Rf_szZ",
        "outputId": "9ec896b0-4ea9-4f6e-947e-00d47b48d1df"
      },
      "source": [
        "# how many time steps/data pts are in one batch of data\n",
        "seq_length = 20\n",
        "\n",
        "# generate evenly spaced data pts\n",
        "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
        "data = np.sin(time_steps)\n",
        "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size(num of features) dimension\n",
        "\n",
        "x = data[:-1] # all but the last piece of data\n",
        "y = data[1:] # all but the first\n",
        "\n",
        "# display the data\n",
        "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
        "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXzklEQVR4nO3df3Bc5X3v8feXtYQywTF3bCclyCDf4EL8G1txETbtBqUzpplIMylk7EDBScDp7fW0TDsmDk18c/EfpoVb5vaapJcE5sYdAgbuHaJwnfFlBHtJ8QKWGkiwTRgZmyI3E1SVGEwRsqVv/zgrVRUr7Vntj6N99vOa0ZzdPc8+5zl7dj979Jyz5zF3R0REat85STdARETKQ4EuIhIIBbqISCAU6CIigVCgi4gEYk5SC16wYIG3tLQktXgRkZrU29v7T+6+MN+8xAK9paWFnp6epBYvIlKTzOz1qeapy0VEJBAKdBGRQCjQRUQCkVgfuojUhzNnztDf38/Q0FDSTakpTU1NNDc309DQEPs5CnQRqaj+/n7mzp1LS0sLZpZ0c2qCuzM4OEh/fz+LFy+O/byCXS5m9oCZvWlmL08x38zsr82sz8x+ZmZrimi3iARuaGiI+fPnK8yLYGbMnz+/6P9q4vSh/y9g4zTzrwGW5P62At8pqgUiVZTNwu7d0TSZCuqTwrx4M3nNCna5uPszZtYyTZFOYK9H1+F9zszON7ML3P2XRbdGpIKyWWhvh+FhaGyE7m5oa6tmBSKVVY6zXC4E3phwvz/32AeY2VYz6zGznoGBgTIsWiS+TCbK4pGRaJrJVLsCScqVV15Z9jpPnDjBD37wg7LXW4qqnrbo7ve5e6u7ty5cmPeXqyLTKqXHI52GxjkjpGyExjkjpNPFV5BNbWC33U42tYHiK8hRt03VHTx4sOx1hhroJ4FFE+435x4TKauxHo9vfjOaFpuHbWTp9nZ2sZNub6eN4irI0ka7dfNNdtFu3WSZQXdLqStRL8r8pXfeeecBkMlkSKfTXHvttVx22WVcf/31jI3a1tLSwm233caKFStYt24dfX19AGzZsoXHHnvsA3Xt2LGDn/zkJ6xevZp77rlnymUfOnSIlStXMjQ0xLvvvsuyZct4+eW855iUrBynLXYB28zsYeC3gFPqP5dKyNfjUVQXdiZD28jf0eb/H0ZSRVeQycDw2RQjDsNnZ7D88UpKWYk6UOFjFT/96U85fPgwH//4x1m/fj3PPvssGzZsAGDevHn8/Oc/Z+/evdx666088cQTU9Zz5513cvfdd09bBuBTn/oUHR0dfOMb3+C9997jhhtuYPny5WVbn4ninLb4EJAFLjWzfjP7ipn9oZn9Ya7IfuA1oA/4LvBHFWmp1L10Ovp8p1LRdCZdJqVUUPLyy1ZJ4Cp8rGLdunU0NzdzzjnnsHr1ak6cODE+b/PmzePTbBn/e9q5cydPPvkkPT093HbbbWWrd7I4Z7lsLjDfgf9cthaJTKGtLdpZy2SiHCx6p63ECkpeftkqCdzYl97YHnqZv/TOPffc8dupVIqzZ8+O3594quDY7Tlz5jA6OgrA6Ogow8PDRS9zcHCQ06dPc+bMGYaGhvjwhz880+ZPS78UlZrS1lZiBpZYQcnLL1slAUvwS2/fvn3s2LGDffv20ZZbbktLC729vXzhC1+gq6uLM2fOADB37lzeeeed8eeePHmSG2+8ke7u7g/U+9WvfpVdu3Zx/Phxvva1r7Fnz56KtF+BLiKzT0Jfem+99RYrV67k3HPP5aGHHgLglltuobOzk1WrVrFx48bxveuVK1eSSqVYtWoVW7Zs4aqrrmLOnA9G6t69e2loaOCLX/wiIyMjXHnllTz11FNcffXVZW+/jR3hrbbW1lbXABf1J5stccer5AqSV2+vwdGjR/nkJz+ZdDMKGht0Z8GCBTN6/p49e7jooovo6OgoW5vyvXZm1uvurfnKaw9dqka/1NRrELJt27Yl3QRdD12qR7/U1Gswm504cWLGe+ezhQJdqibp0w5nA70GUknqcpGqSfq0w9lAr4FUkgJdqirp0w5nA70GUinqchERCYQCXUSC9utf/5pvf/vbVVnW448/zpEjR6qyrHwU6CIStJkEuruP/9y/GAp0EZFJynn13B07dnDs2DFWr17N9u3bOX36NO3t7axZs4YVK1bwwx/+EIhOW7z00ku58cYbWb58OW+88Qa7du3i0ksvZcOGDWzevJm7774bgGPHjrFx40bWrl3LVVddxSuvvMLBgwfp6upi+/btrF69mmPHjuVtz+joKEuWLGFskJ/R0VEuueQSyjLoj7sn8rd27VoXkfAdOXKkqPIHD7p/6EPuqVQ0PXiwtOUfP37cly1bNn7/zJkzfurUKXd3HxgY8E984hM+Ojrqx48fdzPzbDbr7u4vvPCCr1q1yt977z1/++23/ZJLLvG77rrL3d2vvvpqf/XVV93d/bnnnvNPf/rT7u5+0003+aOPPlqwTd/61rf8nnvucXf3AwcO+Oc///m85fK9dkCPT5GrOstFRGaVSl8y3t25/fbbeeaZZzjnnHM4efIkv/rVrwC4+OKLueKKKwB49tln6ezspKmpiaamJj73uc8BcPr0aQ4ePMh11103Xuf7779fVBu+/OUv09nZya233soDDzzAl770pbKsmwJdilJv1yGZjULfBhW+ei4PPvggAwMD9Pb20tDQQEtLC0NDQwCxLms7OjrK+eefz4svvjjjNixatIiPfexjPPXUU7zwwgs8+OCDM65rIvWhS2wlj56m4ddKVg/bYOy3U7t2ledSNZMvc3vq1Ck++tGP0tDQwNNPP83rr7+e93nr16/nRz/6EUNDQ5w+fXp8ZKKPfOQjLF68mEcffRSI9vhfeumlvMvas2fPlJfKvfnmm7nhhhu47rrrSKVSpa1kjgJdYtN1SJJXL9ugrQ2+/vXy/AMxf/581q9fz/Lly9m+fTvXX389PT09rFixgr1793LZZZflfd7Y0HErV67kmmuuYcWKFcybNw+I9vLvv/9+Vq1axbJly8YPrG7atIm77rqLyy+/nGPHjvHKK68wf/78vPV3dHRw+vTpsnW3ADooKvGVfLCq3Ee76lAtboNiD4rOJu+88467u7/77ru+du1a7+3tLer5n/3sZ/3999/PO+/QoUO+YcOGaZ+vg6JSMboOSfK0Dapr69atHDlyhKGhIW666SbWrFlT1POnGkD6zjvv5Dvf+U7Z+s7HaIALEamoWhngYjYqdoAL9aGLSMUlteNYy2byminQRaSimpqaGBwcVKgXwd0ZHBykqampqOepD11EKqq5uZn+/v7y/LS9jjQ1NdHc3FzUcxToIlJRDQ0NLF68OOlm1AV1uYiIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAV6nSl5aK9yjg0midB7IFyxzkM3s43AfwdSwPfc/c5J8y8Cvg+cnyuzw933l7mtUqKxS2GPDRxQ9LWmS65Akqb3QNgK7qGbWQq4F7gGWApsNrOlk4p9A3jE3S8HNgHFDbEtVVEv19KWqek9ELY4XS7rgD53f83dh4GHgc5JZRz4SO72POAfy9dEKZexob1SqRkO7VVyBZI0vQfCVvDyuWZ2LbDR3W/O3f8D4LfcfduEMhcA/w/4D8CHgc+4e2+eurYCWwEuuuiitVMN/SSVE/p4lFKY3gO1bbrL55Yr0P80V9d/M7M24H5gubuPTlWvrocuIlK8Uq+HfhJYNOF+c+6xib4CPALg7lmgCVhQfFNFRGSm4gT6IWCJmS02s0aig55dk8r8A9AOYGafJAp0XStTRKSKCga6u58FtgEHgKNEZ7McNrM7zKwjV+zPgFvM7CXgIWCL62r2IiJVFes89Nw55fsnPbZzwu0jwPryNk1ERIqhX4qKiARCgS4iEggFuohIIBToIiKBUKCLiARCgS4iEggFuohIIBToIiKBUKCLiARCgS4iEggFeo3ReJCSNL0HZ69Y13KR2UHjQUrS9B6c3bSHXkM0HqQkTe/B2U2BXkM0HqQkTe/B2a3gEHSVoiHoZkbjQUrS9B5MVkljilaKAl1EpHiljikqIiI1QIEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhKIWIFuZhvN7Bdm1mdmO6Yo8wUzO2Jmh83sB+VtpoiIFFJwTFEzSwH3Ar8L9AOHzKzL3Y9MKLME+Dqw3t3fMrOPVqrBIiKSX5w99HVAn7u/5u7DwMNA56QytwD3uvtbAO7+ZnmbKSIihcQJ9AuBNybc7889NtFvAr9pZs+a2XNmtjFfRWa21cx6zKxnYGBgZi0WEZG8ynVQdA6wBEgDm4Hvmtn5kwu5+33u3ururQsXLizTomtLNgu7d0fTZCoQSZY+A5VTsA8dOAksmnC/OffYRP3A8+5+BjhuZq8SBfyhsrQyENkstLfD8HA04Hl3d5Fj5JZcgUiy9BmorDh76IeAJWa22MwagU1A16QyjxPtnWNmC4i6YF4rYzuDkMlE78ORkWiayVS7ApFk6TNQWQUD3d3PAtuAA8BR4BF3P2xmd5hZR67YAWDQzI4ATwPb3X2wUo2uVel0tFORSkXTdLraFYgkS5+ByjJ3T2TBra2t3tPTk8iyk5TNRjsV6fQM/1MsuQKRZOkzUBoz63X31rzzFOgiIrVjukDXT/9FRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNCLlM3C7t3RNJkKROqbPoNTm5N0A2pJNgvt7TA8DI2N0N0NbW3VrECkvukzOD3toRchk4neByMj0TSTqXYFIvVNn8HpKdCLkE5HX+qpVDRNp6tdgUh902dweubuiSy4tbXVe3p6Ell2KbLZ6Es9nZ7hf2olVyBS3+r9M2hmve7emneeAl1EpHZMF+jqchERCYQCXUQkEAp0EZFAKNBFRAIRK9DNbKOZ/cLM+sxsxzTlft/M3MzydtiLiEjlFAx0M0sB9wLXAEuBzWa2NE+5ucCfAM+Xu5EiIlJYnD30dUCfu7/m7sPAw0BnnnK7gL8AhsrYPhERiSlOoF8IvDHhfn/usXFmtgZY5O7/d7qKzGyrmfWYWc/AwEDRjRURkamVfFDUzM4B/gr4s0Jl3f0+d29199aFCxeWumgREZkgTqCfBBZNuN+ce2zMXGA5kDGzE8AVQJcOjIqIVFecQD8ELDGzxWbWCGwCusZmuvspd1/g7i3u3gI8B3S4u37XLyJSRQUD3d3PAtuAA8BR4BF3P2xmd5hZR6UbKCIi8cQa4MLd9wP7Jz22c4qy6dKbJSIixdIvRUVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJRN0FejYLu3dH02QqEJEkhZwBsa7lEopsFtrbYXgYGhuhuxva2qpZgYgkKfQMqKs99Ewm2g4jI9E0k6l2BSKSpNAzoK4CPZ2OvlRTqWiaTle7AhFJUugZYO6eyIJbW1u9p6f6Y2Bks9GXajo9w/+USq5ARJJU6xlgZr3unndEuLoLdBGRWjZdoNdVl4uISMgU6CIigVCgi4gEQoEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCAU6CIigYgV6Ga20cx+YWZ9ZrYjz/w/NbMjZvYzM+s2s4vL31QREZlOwUA3sxRwL3ANsBTYbGZLJxX7KdDq7iuBx4C/LHdDRURkenH20NcBfe7+mrsPAw8DnRMLuPvT7v4vubvPAc3lbaaIiBQSJ9AvBN6YcL8/99hUvgL8ON8MM9tqZj1m1jMwMBC/lSIiUlBZD4qa2Q1AK3BXvvnufp+7t7p768KFC8u5aBGRujcnRpmTwKIJ95tzj/07ZvYZ4M+B33H398vTPBERiSvOHvohYImZLTazRmAT0DWxgJldDvxPoMPd3yx/M0VEpJCCge7uZ4FtwAHgKPCIux82szvMrCNX7C7gPOBRM3vRzLqmqE5ERCokTpcL7r4f2D/psZ0Tbn+mzO0SEZEi6ZeiIiKBqLlAz2Zh9+5omkwFIlLPZnMGxepymS2yWWhvh+FhaGyE7m5oa6tmBSJSz2Z7BtXUHnomE70OIyPRNJOpdgUiUs9mewbVVKCn09GXWioVTdPpalcgIvVstmeQuXtZK4yrtbXVe3p6in5eNht9qaXTM/xPpeQKRKSeJZ1BZtbr7q1559VaoIuI1LPpAr2mulxERGRqCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJRKxAN7ONZvYLM+szsx155p9rZvty8583s5ZyN1RERKZXMNDNLAXcC1wDLAU2m9nSScW+Arzl7pcA9wB/Ue6GjstmYffuaCoiUmMqGWFzYpRZB/S5+2sAZvYw0AkcmVCmE/hW7vZjwB4zM3f3MrY1egXa22F4GBobobsb2trKuggRkUqpdITF6XK5EHhjwv3+3GN5y7j7WeAUMH9yRWa21cx6zKxnYGCg+NZmMtErMTISTTOZ4usQEUlIpSOsqgdF3f0+d29199aFCxcWX0E6HX2tpVLRNJ0udxNFRCqm0hEWp8vlJLBowv3m3GP5yvSb2RxgHjBYlhZO1NYW/Y+SyUSvhLpbRKSGVDrC4gT6IWCJmS0mCu5NwBcnlekCbgKywLXAU2XvPx/T1qYgF5GaVckIKxjo7n7WzLYBB4AU8IC7HzazO4Aed+8C7gf+1sz6gH8mCn0REamiOHvouPt+YP+kx3ZOuD0EXFfepomISDH0S1ERkUAo0EVEAqFAFxEJhAJdRCQQVqmzCwsu2GwAeD2RhZfXAuCfkm5EmWhdZiety+yU1Lpc7O55f5mZWKCHwsx63L016XaUg9ZldtK6zE6zcV3U5SIiEggFuohIIBTopbsv6QaUkdZldtK6zE6zbl3Uhy4iEgjtoYuIBEKBLiISCAV6TDEGyt5iZgNm9mLu7+Yk2lmImT1gZm+a2ctTzDcz++vcev7MzNZUu41xxViXtJmdmrBNduYrNxuY2SIze9rMjpjZYTP7kzxlamLbxFyXmtg2ZtZkZi+Y2Uu5dfmvecqca2b7ctvleTNrqX5Lc9xdfwX+iC4bfAz4j0Aj8BKwdFKZLcCepNsaY11+G1gDvDzF/N8DfgwYcAXwfNJtLmFd0sATSbcz5rpcAKzJ3Z4LvJrnPVYT2ybmutTEtsm91uflbjcAzwNXTCrzR8Df5G5vAvYl1V7tocczPlC2uw8DYwNl1xx3f4bomvVT6QT2euQ54Hwzu6A6rStOjHWpGe7+S3f/+9ztd4CjfHDs3prYNjHXpSbkXuvTubsNub/JZ5J0At/P3X4MaDczq1IT/x0FejxxBsoG+P3cv8KPmdmiPPNrQdx1rRVtuX+Xf2xmy5JuTBy5f9kvJ9obnKjmts006wI1sm3MLGVmLwJvAk+6+5Tbxd3PAqeA+dVtZUSBXj4/AlrcfSXwJP/2jS3J+Xui616sAv4H8HjC7SnIzM4D/jdwq7u/nXR7SlFgXWpm27j7iLuvJhpPeZ2ZLU+6TVNRoMdTcKBsdx909/dzd78HrK1S28otzqDgNcHd3x77d9mjUbcazGxBws2akpk1EAXgg+7+f/IUqZltU2hdam3bALj7r4GngY2TZo1vFzObA8wDBqvbuogCPZ7xgbLNrJHowEfXxAKT+jI7iPoNa1EXcGPujIorgFPu/sukGzUTZvYbY32ZZraO6P2eyAetkFw77weOuvtfTVGsJrZNnHWplW1jZgvN7Pzc7Q8Bvwu8MqlYF3BT7va1wFOeO0JabbHGFK13Hm+g7D82sw7gLNGBui2JNXgaZvYQ0RkGC8ysH/gvRAd6cPe/IRo79veAPuBfgC8l09LCYqzLtcB/MrOzwHvApqQ+aDGsB/4A+HmuvxbgduAiqLltE2ddamXbXAB838xSRF86j7j7E5M++/cDf2tmfUSf/U1JNVY//RcRCYS6XEREAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQ/wrXbM/fhh4F2QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrK8foRdACEr",
        "outputId": "e93d733f-cadc-4d1a-eb58-d54f86b41fcc"
      },
      "source": [
        "print('time_steps size:', time_steps.shape)\n",
        "print('data size:', data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time_steps size: (21,)\n",
            "data size: (21, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM6Zo3EwE-dP"
      },
      "source": [
        "## **Define the RNN**\n",
        "Next, we define an RNN in PyTorch. We'll use nn.RNN to create an RNN layer, then we'll add a last, fully-connected layer to get the output size that we want. An RNN takes in a number of parameters:\n",
        "\n",
        "* **input_size** - the size of the input\n",
        "* **hidden_dim** - the number of features in the RNN output and in the hidden state\n",
        "* **n_layers** - the number of layers that make up the RNN, typically 1-3; greater than 1 means that you'll create a stacked RNN\n",
        "* **batch_first** - whether or not the input/output of the RNN will have the batch_size as the first dimension (batch_size, seq_length, hidden_dim)\n",
        "Take a look at the [RNN documentation](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) to read more about recurrent layers.\n",
        "\n",
        "After creating an RNN instance, the input of the RNN model should be:\n",
        "* **input** : tensor of shape `(L, N, H_in)` when `batch_first=False` or `(N, L, H_in)` when `batch_first=True` containing the features of the input sequence. \n",
        "* **h_0** : tensor of shape `(D * num_layers, N, H_out)` containing the initial hidden state for each element in the batch. Defaults to zeros if not provided.\n",
        "\n",
        "The output:\n",
        "* **output** : tensor of shape `(L, N, D * H_out)` when `batch_first=False` or `(N, L, D * H_out)` when `batch_first=True` containing the output features (`h_t`) from the last layer of the RNN, for each `t`.\n",
        "\n",
        "* **h_n** : tensor of shape (D * num_layers, N, H_out) containing the final hidden state for each element in the batch.\n",
        "\n",
        "Where \n",
        "* `N` = batch size\n",
        "* `L` = sequence length\n",
        "* `D` = 2 if bidirectional=True otherwise 1\n",
        "* `H_in` = input_size\n",
        "* `H_out` = hidden_size (i.e. hidden_dim)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvkqwx5AV1H"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # define an RNN with specified parameters\n",
        "        # batch_first means that the first dim of the input and output will be the batch_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        # last, fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x (batch_size, seq_length, input_size)\n",
        "        # hidden (n_layers, batch_size, hidden_dim)\n",
        "        # r_out (batch_size, time_step, hidden_size)\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # get RNN outputs\n",
        "        r_out, hidden = self.rnn(x, hidden) # This produce the RNN output and a new hidden state\n",
        "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
        "        # This is a flattening step where I'm preparing the output to be fed into a fully-connected layer\n",
        "        r_out = r_out.view(-1, self.hidden_dim) \n",
        "\n",
        "        # get final output\n",
        "        output = self.fc(r_out)\n",
        "\n",
        "        return output, hidden"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnvuuZz6OkI-"
      },
      "source": [
        "### **Check the input and output dimensions**\n",
        "As a check that your model is working as expected, test out how it responds to input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqFSsnu1Ojvh",
        "outputId": "d2c3504e-6597-47a6-e743-deea06e05f24"
      },
      "source": [
        "# test that dimensions are as expected\n",
        "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
        "\n",
        "# generate evenly spaced, test data pts\n",
        "time_steps = np.linspace(0, np.pi, seq_length)\n",
        "data = np.sin(time_steps)\n",
        "data.resize((seq_length, 1))\n",
        "\n",
        "test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension\n",
        "print('Input size:', test_input.size())\n",
        "\n",
        "# test out rnn sizes\n",
        "test_out, test_h = test_rnn(test_input, None)\n",
        "print('Output size: ', test_out.size())\n",
        "print('Hidden state size: ', test_h.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size: torch.Size([1, 20, 1])\n",
            "Output size:  torch.Size([20, 1])\n",
            "Hidden state size:  torch.Size([2, 1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3cII6NWcK4"
      },
      "source": [
        "The output size is a 2D tensor. This is because in the forward function of our model definition smooshed the batch size and seqence length into one parameter (batch_size * seq_length, hidden_dim) = (20, 1).\n",
        "\n",
        "The final hidden state size is (n_layers, batch_size, H_out) = (2, 1, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MvS1iecX7LF"
      },
      "source": [
        "## **Training the RNN**\n",
        "Next, we'll instantiate an RNN with some specified hyperparameters. Then train it over a series of steps, and see how it performs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w5skXBPQGMM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}